{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Example 1\n",
    "For this example, we have images of cars and flowers, which have been divided into training and testing sets, and we have to build a CNN that identifies whether an image is a car or a flower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import the numpy library and the necessary Keras libraries and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists for training images, no need to organise data\n"
     ]
    }
   ],
   "source": [
    "# Import the Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow import random\n",
    "import os, logging, glob\n",
    "from _data import organise_images_in_folders\n",
    "from _logging import set_logging\n",
    "\n",
    "set_logging(logging)\n",
    "set_up_flag = True\n",
    "if set_up_flag:\n",
    "    organise_images_in_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Now, set a seed and initiate the model with the `Sequential` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a seed\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.set_seed(seed)\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Add the first layer of the CNN, set the input shape to (64, 64, 3), the dimension of each image, and set the activation function as a ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsOfImage, columnsOfImage = 64, 64\n",
    "input_shape = (rowsOfImage, columnsOfImage, 3)\n",
    "classifier.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Now, add the pooling layer with the image size as 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPool2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Flatten the output of the pooling layer by adding a flattening layer to the CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Add the first Dense layer of the MLP. \n",
    "Here, 128 is the output of the number of nodes. As a good practice, 128 is good to get started. activation is relu. As a good practice, the power of two is preferred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(128, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Add the output layer of the MLP.\n",
    "This is a binary classification problem, so the size is 1 and the activation is `sigmoid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Compile the network\n",
    "Use an adam optimizer and compute the accuracy during the training process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerAdam = Adam(name = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Create training and test data generators. \n",
    "- Rescale the training and test images by `1/255` so that all the values are between `0` and `1`.\n",
    "- Set these parameters for the training data generators only \n",
    " - `shear_range=0.2`, `zoom_range=0.2`, and `horizontal_flip=True`\n",
    " \n",
    " - https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"car_flower_small\"\n",
    "dir_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create a training set from the training set folder.\n",
    "'training_set' is the folder where our data has been placed. Our CNN model has an image size of `64x64`, so the same size should be passed here too. `batch_size` is the number of images in a single batch, which is `32`. `Class_mode` is set to binary since we are working on binary classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1497 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a generator that will read pictures found in\n",
    "# subfolders of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "batch_size = 32\n",
    "image_size = (64, 64)\n",
    "train_directory = os.path.join(\"car_flower_small\", \"data\", \"trainset\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_directory,  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Repeat step 10 for the test set \n",
    "while setting the folder to the location of the test images, that is, 'test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a similar generator, for validation data\n",
    "test_directory = os.path.join(\"car_flower_small\", \"data\", \"testset\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_directory,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Finally, fit the data. \n",
    "Set the `steps_per_epoch` to `STEP_SIZE_TRAIN` and the `validation_steps` to `STEP_SIZE_TEST`. \n",
    "\n",
    "Why do we need `steps_per_epoch` ?\n",
    "\n",
    "Keep in mind that a Keras data generator is meant to loop infinitely — it should never return or exit.\n",
    "\n",
    "Since the function is intended to loop infinitely, Keras has no ability to determine when one epoch starts and a new epoch begins.\n",
    "\n",
    "Therefore, we compute the `steps_per_epoch` value as the total number of training data points divided by the batch size. Once Keras hits this step count it knows that it’s a new epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-18 18:06:25,441 | INFO : train_steps_per_epoch = 46\n",
      "2023-01-18 18:06:25,441 | INFO : test_steps_per_epoch = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hijik\\AppData\\Local\\Temp\\ipykernel_8124\\2125813100.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 6s 126ms/step - loss: 0.9253 - accuracy: 0.6307 - val_loss: 0.5713 - val_accuracy: 0.7375\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.5083 - accuracy: 0.7625 - val_loss: 0.5057 - val_accuracy: 0.7563\n",
      "Epoch 3/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.4453 - accuracy: 0.8082 - val_loss: 0.5852 - val_accuracy: 0.7104\n",
      "Epoch 4/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.4331 - accuracy: 0.7918 - val_loss: 0.5418 - val_accuracy: 0.7479\n",
      "Epoch 5/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.3980 - accuracy: 0.8314 - val_loss: 0.5075 - val_accuracy: 0.7729\n",
      "Epoch 6/50\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.3726 - accuracy: 0.8307 - val_loss: 0.4801 - val_accuracy: 0.7729\n",
      "Epoch 7/50\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.3726 - accuracy: 0.8341 - val_loss: 0.4853 - val_accuracy: 0.7750\n",
      "Epoch 8/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.3559 - accuracy: 0.8444 - val_loss: 0.5093 - val_accuracy: 0.7667\n",
      "Epoch 9/50\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.3438 - accuracy: 0.8478 - val_loss: 0.5420 - val_accuracy: 0.7521\n",
      "Epoch 10/50\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.3340 - accuracy: 0.8662 - val_loss: 0.6709 - val_accuracy: 0.7208\n",
      "Epoch 11/50\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.3375 - accuracy: 0.8519 - val_loss: 0.4811 - val_accuracy: 0.7854\n",
      "Epoch 12/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.3323 - accuracy: 0.8662 - val_loss: 0.4698 - val_accuracy: 0.7729\n",
      "Epoch 13/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.3331 - accuracy: 0.8505 - val_loss: 0.5083 - val_accuracy: 0.7917\n",
      "Epoch 14/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.3060 - accuracy: 0.8737 - val_loss: 0.5821 - val_accuracy: 0.7896\n",
      "Epoch 15/50\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.2942 - accuracy: 0.8662 - val_loss: 0.5044 - val_accuracy: 0.7833\n",
      "Epoch 16/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.2914 - accuracy: 0.8758 - val_loss: 0.4921 - val_accuracy: 0.7688\n",
      "Epoch 17/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.2819 - accuracy: 0.8826 - val_loss: 0.5451 - val_accuracy: 0.7708\n",
      "Epoch 18/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.2771 - accuracy: 0.8833 - val_loss: 0.5344 - val_accuracy: 0.7771\n",
      "Epoch 19/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.2548 - accuracy: 0.8949 - val_loss: 0.5147 - val_accuracy: 0.8042\n",
      "Epoch 20/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.2603 - accuracy: 0.8901 - val_loss: 0.5667 - val_accuracy: 0.7708\n",
      "Epoch 21/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.2603 - accuracy: 0.8805 - val_loss: 0.5302 - val_accuracy: 0.7937\n",
      "Epoch 22/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.2539 - accuracy: 0.8940 - val_loss: 0.5936 - val_accuracy: 0.7750\n",
      "Epoch 23/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.2483 - accuracy: 0.9010 - val_loss: 0.5738 - val_accuracy: 0.7896\n",
      "Epoch 24/50\n",
      "46/46 [==============================] - 5s 103ms/step - loss: 0.2304 - accuracy: 0.9044 - val_loss: 0.7801 - val_accuracy: 0.7604\n",
      "Epoch 25/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.1925 - accuracy: 0.9276 - val_loss: 0.6507 - val_accuracy: 0.7792\n",
      "Epoch 26/50\n",
      "46/46 [==============================] - 5s 105ms/step - loss: 0.2161 - accuracy: 0.9137 - val_loss: 0.5316 - val_accuracy: 0.7896\n",
      "Epoch 27/50\n",
      "46/46 [==============================] - 5s 105ms/step - loss: 0.2038 - accuracy: 0.9160 - val_loss: 0.7064 - val_accuracy: 0.7812\n",
      "Epoch 28/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.1952 - accuracy: 0.9188 - val_loss: 0.6304 - val_accuracy: 0.7646\n",
      "Epoch 29/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.1803 - accuracy: 0.9263 - val_loss: 0.5986 - val_accuracy: 0.7875\n",
      "Epoch 30/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.1666 - accuracy: 0.9345 - val_loss: 0.6655 - val_accuracy: 0.7750\n",
      "Epoch 31/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.1982 - accuracy: 0.9215 - val_loss: 0.5607 - val_accuracy: 0.7917\n",
      "Epoch 32/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.1566 - accuracy: 0.9406 - val_loss: 0.6179 - val_accuracy: 0.7896\n",
      "Epoch 33/50\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.1447 - accuracy: 0.9406 - val_loss: 0.6475 - val_accuracy: 0.7937\n",
      "Epoch 34/50\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.1597 - accuracy: 0.9352 - val_loss: 0.6569 - val_accuracy: 0.7937\n",
      "Epoch 35/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.1932 - accuracy: 0.9174 - val_loss: 0.7347 - val_accuracy: 0.7563\n",
      "Epoch 36/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.1892 - accuracy: 0.9188 - val_loss: 0.7148 - val_accuracy: 0.7812\n",
      "Epoch 37/50\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.1316 - accuracy: 0.9536 - val_loss: 0.7504 - val_accuracy: 0.7875\n",
      "Epoch 38/50\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.1387 - accuracy: 0.9454 - val_loss: 0.7272 - val_accuracy: 0.7563\n",
      "Epoch 39/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.1541 - accuracy: 0.9399 - val_loss: 0.7539 - val_accuracy: 0.7792\n",
      "Epoch 40/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.1214 - accuracy: 0.9495 - val_loss: 0.8051 - val_accuracy: 0.7646\n",
      "Epoch 41/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.1347 - accuracy: 0.9549 - val_loss: 0.7944 - val_accuracy: 0.7937\n",
      "Epoch 42/50\n",
      "46/46 [==============================] - 5s 102ms/step - loss: 0.1131 - accuracy: 0.9611 - val_loss: 0.7346 - val_accuracy: 0.8125\n",
      "Epoch 43/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.1112 - accuracy: 0.9577 - val_loss: 0.8003 - val_accuracy: 0.7917\n",
      "Epoch 44/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.0898 - accuracy: 0.9672 - val_loss: 0.9720 - val_accuracy: 0.7396\n",
      "Epoch 45/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.1359 - accuracy: 0.9447 - val_loss: 1.0274 - val_accuracy: 0.7750\n",
      "Epoch 46/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.1369 - accuracy: 0.9474 - val_loss: 0.8173 - val_accuracy: 0.7833\n",
      "Epoch 47/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.1319 - accuracy: 0.9447 - val_loss: 1.0444 - val_accuracy: 0.7729\n",
      "Epoch 48/50\n",
      "46/46 [==============================] - 5s 100ms/step - loss: 0.1030 - accuracy: 0.9597 - val_loss: 0.9937 - val_accuracy: 0.7896\n",
      "Epoch 49/50\n",
      "46/46 [==============================] - 5s 104ms/step - loss: 0.0931 - accuracy: 0.9611 - val_loss: 0.8285 - val_accuracy: 0.8125\n",
      "Epoch 50/50\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.1046 - accuracy: 0.9556 - val_loss: 0.8904 - val_accuracy: 0.7729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x244955b4ca0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizerAdam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "_train_steps_per_epoch = len(train_generator.filenames) // batch_size\n",
    "_test_steps_per_epoch = len(test_generator.filenames) // batch_size\n",
    "logging.info(f\"train_steps_per_epoch = {_train_steps_per_epoch}\")\n",
    "logging.info(f\"test_steps_per_epoch = {_test_steps_per_epoch}\")\n",
    "classifier.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=_train_steps_per_epoch,\n",
    "        epochs=50,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=_test_steps_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b41ba045e83f0be7a0a86cbeef029bed6bb1f3047ea5aef815a52ba8b6ba543c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
